---
layout: post
title: k-means
hn:
categories:
- blog
---

[k-means](http://en.wikipedia.org/wiki/K-means_clustering) clustering is a neat way to group points into groups and combine
those groups into fewer points. I first noticed it in
[a web map example](http://polymaps.org/ex/cluster.html)
that clusters crime data into pretty circles, but it took a while to
get to the 'aha' moment as far as the principle and behavior.

The common algorithm for calculating k-means is a [heuristic](http://en.wikipedia.org/wiki/Heuristic):
it comes up with a viable solution but not necessarily the best one.
Calculating the true, perfect k-means would take a whole lot longer, and offer
only a marginal improvement.

The strategy starts with _random points_, so each time it runs,
the results are different, even if the source data is the same:

![](https://dl.dropbox.com/u/68059/graphics/kmeans.gif)

k-means is just complicated enough to be tricky to visualize, but it's easier
if you take advantage of the fact that the data can be in `d` dimensions.
On maps, we're using 2D k-means; sometimes 3D is used for colors. 1D is less
popular, but is much easier to visualize.

The input to this version of the algorithm will be a simple one-dimensional
set of numbers, and a **k value** - which indicates how many clusters (means)
should be produced. Valid k values can be between 1 and the size of the
dataset: you can't have more clusters than you have data points.

<img src='/graphics/kmeans-input.png' width='640' height='50' />

## Boundary Cases

If this _k_ value is equal to the size of the data itself, then the set
of clusters is the same as the input:

<img src='/graphics/kmeans-same.png' width='640' height='100' />

If this _k_ value is one, then the eventual output will be the global mean:

<img src='/graphics/kmeans-one.png' width='640' height='100' />

## Algorithm

In common usage, you'll provide a dataset that's of `n` values and
your `k` number will be less than that number of values but greater
than one - so you're trying to derive multiple clusters from the data.

The heuristic for this case chooses k _random values_ from that dataset.

<img src='/graphics/kmeans-choose.png' width='640' height='100' />

These values are the _potential means_ - hence `k-means`. But since
we just chose them randomly, they likely aren't that good - they
might even be terribly lopsided, inhabiting only one small part of
the dataset.

## k-means + cartography

k-means has some application in cartography - for finding centers of density
in 2d space. However, it's a different problem and a different solution
than point clustering that intends to reduce visual noise and overlapping
shapes - k-means is _not sensitive to symbolization_ and thus deals with
euclidean points that inhabit no space. So if your dataset is heavily
concentrated in a certain area, cluster centers will be too, and the
resulting map won't be 'clean'.
