---
layout: post
title: k-means
categories:
- blog
---

[k-means](http://en.wikipedia.org/wiki/K-means_clustering) clustering is a
neat way to show density by combining points into 'cluster centers'.

![](https://dl.dropbox.com/u/68059/graphics/kmeans.gif)
<span class='image-credit'><a href='http://polymaps.org/ex/cluster.html'>k-means clusters with polymaps</a></span>

The most popular algorithm for calculating k-means is a
_[heuristic](http://en.wikipedia.org/wiki/Heuristic)_:
it comes up with a viable solution but not necessarily the best one.
Calculating the true, perfect k-means would take a whole lot longer, and offer
only a marginal improvement. It's also _iterative_: it refines a guess
repeatedly until it's 'good enough.'

k-means is tricky to visualize in its common 2d form - It's easier
if you take advantage of the fact that the data can be in `d` dimensions and
focus on one-dimensional data, like a list of numbers.

The input to k-means is a d-dimensional
dataset, and a **k value** - which indicates how many clusters (means)
should be produced. Valid k values can be between 1 and the size of the
dataset: you can't have more clusters than you have data points.


## Boundary Cases

If this _k_ value is equal to the size of the data itself, then the set
of clusters is the same as the input:

If this _k_ value is one, then the eventual output will be the global mean:

## Algorithm

In common usage, you'll provide a dataset that's of `n` values and
your `k` number will be less than that number of values but greater
than one - so you're trying to derive multiple clusters from the data.

The heuristic for this case chooses k _random values_ from that dataset.

These values are the _potential means_ - hence `k-means`. But since
we just chose them randomly, they likely aren't that good - they
might even be terribly lopsided, inhabiting only one small part of
the dataset.

## k-means + cartography

k-means has some application in cartography - for finding centers of density
in 2d space. However, it's a different problem and a different solution
than point clustering that intends to reduce visual noise and overlapping
shapes - k-means is _not sensitive to symbolization_ and thus deals with
euclidean points that inhabit no space. So if your dataset is heavily
concentrated in a certain area, cluster centers will be too, and the
resulting map won't be 'clean'.
